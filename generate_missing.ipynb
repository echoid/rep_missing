{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname_list = [\"banknote\",\"yeast\",\"climate_model_crashes\",\n",
    "                 \"wine_quality_white\", \"yacht_hydrodynamics\",\"concrete_compression\",\n",
    "                 \"breast_cancer\",\"solar_fire\",\"car_evluation\"\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_split_index_cv(scaled_data, directory_path, seed=1, nfold=5):\n",
    "    indlist = np.arange(len(scaled_data))\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(indlist)\n",
    "\n",
    "    fold_size = len(scaled_data) // nfold\n",
    "    save_index = {}\n",
    "\n",
    "    for fold in range(nfold):\n",
    "        start = fold * fold_size\n",
    "        end = start + fold_size if fold < nfold - 1 else len(scaled_data)\n",
    "        \n",
    "        test_index = indlist[start:end]\n",
    "        train_index = np.concatenate([indlist[:start], indlist[end:]])\n",
    "\n",
    "        # If you want to split the training set into train and validation sets\n",
    "        num_train = int(len(train_index) * 0.9)\n",
    "        train_subindex = train_index[:num_train]\n",
    "        valid_subindex = train_index[num_train:]\n",
    "\n",
    "        fold_index = {\n",
    "            \"test_index\": test_index.astype(np.int64).tolist(),\n",
    "            \"train_index\": train_subindex.astype(np.int64).tolist(),\n",
    "            \"valid_index\": valid_subindex.astype(np.int64).tolist()\n",
    "        }\n",
    "        save_index[f\"fold_{fold+1}\"] = fold_index\n",
    "\n",
    "    with open(f\"data/{directory_path}/split_index_cv_seed-{seed}_nfold-{nfold}.json\", 'w') as file:\n",
    "        json.dump(save_index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    if name == \"banknote\":\n",
    "        with open('data/banknote/data_banknote_authentication.txt', 'rb') as f:\n",
    "            df = pd.read_csv(f, low_memory=False, sep=',',header = None)\n",
    "            Xy = {}\n",
    "            # Ignore the two blocking factor\n",
    "            Xy['data'] = df.values[:, :-1]\n",
    "            Xy['target'] =  df.values[:, -1]\n",
    "    elif name == \"yeast\":\n",
    "        with open('data/yeast/yeast.data', 'rb') as f:\n",
    "            df = pd.read_csv(f, delimiter='\\s+', header = None)\n",
    "            Xy = {}\n",
    "            # remove index\n",
    "            Xy['data'] = df.values[:, 1:-1].astype('float')\n",
    "            Xy['target'] =  df.values[:, -1]\n",
    "    elif name == \"climate_model_crashes\":\n",
    "        with open('data/climate_model_crashes/pop_failures.dat', 'rb') as f:\n",
    "            df = pd.read_csv(f, delimiter='\\s+', header = 0)\n",
    "            Xy = {}\n",
    "            # Ignore the two blocking factor\n",
    "            Xy['data'] = df.values[:, 2:-1]\n",
    "            Xy['target'] =  df.values[:, -1]\n",
    "    elif name == \"wine_quality_white\":\n",
    "        with open('data/wine_quality_white/data.csv', 'rb') as f:\n",
    "            df = pd.read_csv(f, delimiter=';')\n",
    "            Xy = {}\n",
    "            Xy['data'] = df.values[:, :-1].astype('float')\n",
    "            Xy['target'] =  df.values[:, -1]\n",
    "\n",
    "    elif name == \"yacht_hydrodynamics\":\n",
    "        with open('data/yacht_hydrodynamics/yacht_hydrodynamics.data', 'rb') as f:\n",
    "            df = pd.read_csv(f, delimiter='\\s+', header = None)\n",
    "            Xy = {}\n",
    "            Xy['data'] = df.values[:, :-1]\n",
    "            Xy['target'] =  df.values[:, -1]\n",
    "\n",
    "    elif name == \"concrete_compression\":\n",
    "        with open('data/concrete_compression/Concrete_Data.xls', 'rb') as f:\n",
    "            df = pd.read_excel(io=f)\n",
    "            Xy = {}\n",
    "            Xy['data'] = df.values[:, :-1]\n",
    "            Xy['target'] =  df.values[:, -1]\n",
    "\n",
    "    elif name == \"breast_cancer\":\n",
    "        with open('data/breast_cancer/breast_cancer.data', 'rb') as f:\n",
    "            df = pd.read_csv(f, delimiter=',', header = None)\n",
    "            Xy = {}\n",
    "            Xy['data'] = df.values[:, :-1]\n",
    "            Xy['target'] =  df.values[:, -1]\n",
    "\n",
    "    elif name == \"solar_fire\":\n",
    "        with open('data/solar_fire/flare.data1', 'rb') as f:\n",
    "            df1 = pd.read_csv(f, delimiter='\\s+', header = None)\n",
    "        with open('data/solar_fire/flare.data2', 'rb') as f:\n",
    "            df2 = pd.read_csv(f, delimiter='\\s+', header = None)\n",
    "            df = pd.concat([df1, df2], ignore_index=True)\n",
    "            Xy = {}\n",
    "            Xy['data'] = df.values[:, :-1]\n",
    "            Xy['target'] =  df.values[:, -1]\n",
    "\n",
    "    elif name == \"car_evaluation\":\n",
    "        with open('data/car_evaluation/car.data', 'rb') as f:\n",
    "            df = pd.read_csv(f, delimiter=',', header = None)\n",
    "            Xy = {}\n",
    "            Xy['data'] = df.values[:, :-1]\n",
    "            Xy['target'] =  df.values[:, -1]\n",
    "\n",
    "    return Xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04956268 0.04956268 0.04956268 0.04956268] 0.04956268221574344\n",
      "[0.09985423 0.09985423 0.09985423 0.09985423] 0.09985422740524781\n",
      "[0.29956268 0.29956268 0.29956268 0.29956268] 0.29956268221574345\n",
      "[0.5 0.5 0.5 0.5] 0.5\n",
      "\n",
      "[0.04986523 0.04986523 0.04986523 0.04986523 0.04986523 0.04986523\n",
      " 0.04986523 0.04986523] 0.04986522911051213\n",
      "[0.09973046 0.09973046 0.09973046 0.09973046 0.09973046 0.09973046\n",
      " 0.09973046 0.09973046] 0.09973045822102426\n",
      "[0.29986523 0.29986523 0.29986523 0.29986523 0.29986523 0.29986523\n",
      " 0.29986523 0.29986523] 0.2998652291105121\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5] 0.5\n",
      "\n",
      "[0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05] 0.05\n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1] 0.1\n",
      "[0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3] 0.3\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5] 0.5\n",
      "\n",
      "[0.04981625 0.04981625 0.04981625 0.04981625 0.04981625 0.04981625\n",
      " 0.04981625 0.04981625 0.04981625 0.04981625 0.04981625] 0.04981625153123724\n",
      "[0.09983667 0.09983667 0.09983667 0.09983667 0.09983667 0.09983667\n",
      " 0.09983667 0.09983667 0.09983667 0.09983667 0.09983667] 0.09983666802776643\n",
      "[0.29991833 0.29991833 0.29991833 0.29991833 0.29991833 0.29991833\n",
      " 0.29991833 0.29991833 0.29991833 0.29991833 0.29991833] 0.29991833401388324\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5] 0.5\n",
      "\n",
      "[0.0487013 0.0487013 0.0487013 0.0487013 0.0487013 0.0487013] 0.048701298701298704\n",
      "[0.0974026 0.0974026 0.0974026 0.0974026 0.0974026 0.0974026] 0.09740259740259741\n",
      "[0.2987013 0.2987013 0.2987013 0.2987013 0.2987013 0.2987013] 0.2987012987012987\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5] 0.5\n",
      "\n",
      "[0.04951456 0.04951456 0.04951456 0.04951456 0.04951456 0.04951456\n",
      " 0.04951456 0.04951456] 0.04951456310679612\n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1] 0.1\n",
      "[0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3] 0.3\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5] 0.5\n",
      "\n",
      "[0.04895105 0.04895105 0.04895105 0.04895105 0.04895105 0.04895105\n",
      " 0.04895105 0.04895105 0.04895105] 0.04895104895104895\n",
      "[0.0979021 0.0979021 0.0979021 0.0979021 0.0979021 0.0979021 0.0979021\n",
      " 0.0979021 0.0979021] 0.0979020979020979\n",
      "[0.2972028 0.2972028 0.2972028 0.2972028 0.2972028 0.2972028 0.2972028\n",
      " 0.2972028 0.2972028] 0.2972027972027972\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5] 0.5\n",
      "\n",
      "[0.04967603 0.04967603 0.04967603 0.04967603 0.04967603 0.04967603\n",
      " 0.04967603 0.04967603 0.04967603 0.04967603 0.04967603 0.04967603] 0.04967602591792657\n",
      "[0.09935205 0.09935205 0.09935205 0.09935205 0.09935205 0.09935205\n",
      " 0.09935205 0.09935205 0.09935205 0.09935205 0.09935205 0.09935205] 0.09935205183585313\n",
      "[0.29949604 0.29949604 0.29949604 0.29949604 0.29949604 0.29949604\n",
      " 0.29949604 0.29949604 0.29949604 0.29949604 0.29949604 0.29949604] 0.2994960403167747\n",
      "[0.49964003 0.49964003 0.49964003 0.49964003 0.49964003 0.49964003\n",
      " 0.49964003 0.49964003 0.49964003 0.49964003 0.49964003 0.49964003] 0.4996400287976962\n",
      "\n",
      "[0.04976852 0.04976852 0.04976852 0.04976852 0.04976852 0.04976852] 0.04976851851851852\n",
      "[0.09953704 0.09953704 0.09953704 0.09953704 0.09953704 0.09953704] 0.09953703703703703\n",
      "[0.29976852 0.29976852 0.29976852 0.29976852 0.29976852 0.29976852] 0.29976851851851855\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5] 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataname_list = [\"banknote\",\"yeast\",\"climate_model_crashes\",\n",
    "                 \"wine_quality_white\", \"yacht_hydrodynamics\",\"concrete_compression\",\n",
    "                 \"breast_cancer\",\"solar_fire\",\"car_evaluation\"\n",
    "                 ]\n",
    "save = False\n",
    "missing_rate = [0.05, 0.1, 0.3, 0.5] \n",
    "\n",
    "\n",
    "for name in dataname_list:\n",
    "    for p in missing_rate:\n",
    "        Xy = load_data(name)\n",
    "        \n",
    "        feature = Xy['data']\n",
    "        label = Xy['target']\n",
    "\n",
    "        MCAR_mask = MCAR(feature, p, seed=1)\n",
    "        # MAR_mask = MCAR(feature, p, seed=1)\n",
    "        # MNAR_mask = MNAR(feature, p, seed=1)\n",
    "        \n",
    "        \n",
    "\n",
    "        if save:\n",
    "            save_split_index_cv(Xy['data'],name,seed = 1,nfold = 5)\n",
    "            np.save(f\"data/{name}/feature.npy\", Xy['data'])\n",
    "            np.save(f\"data/{name}/label.npy\", Xy['target'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Mechan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCAR(observed_values, p, seed=1):\n",
    "    np.random.seed(seed)\n",
    "    num_rows, num_cols = observed_values.shape\n",
    "    num_to_remove_per_column = int(num_rows * p)\n",
    "    masks = np.ones_like(observed_values)\n",
    "    for col in range(num_cols):\n",
    "        indices_to_remove = np.random.choice(num_rows, num_to_remove_per_column, replace=False)\n",
    "        masks[indices_to_remove, col] = 0\n",
    "    #calculate_missing_rates(masks)\n",
    "    return masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_missing_rates(mask):\n",
    "    # Calculate missing rate for each column\n",
    "    num_rows, num_cols = mask.shape\n",
    "    missing_rate_per_column = np.sum(mask == 0, axis=0) / num_rows\n",
    "\n",
    "    # Calculate overall missing rate\n",
    "    total_elements = num_rows * num_cols\n",
    "    overall_missing_rate = np.sum(mask == 0) / total_elements\n",
    "\n",
    "    print(missing_rate_per_column, overall_missing_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
