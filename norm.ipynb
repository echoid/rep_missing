{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(string):\n",
    "    parts = string.split(\"/\")[1].split(\"_\")\n",
    "\n",
    "    # Get the information from the middle\n",
    "    information = \"_\".join(parts[:-1])\n",
    "\n",
    "    return information\n",
    "\n",
    "def run_norm(path_train_data, type = \"data/mean_\"):\n",
    "    # Read data from file\n",
    "    print(path_train_data)\n",
    "    \n",
    "    data = np.genfromtxt(path_train_data, delimiter=',', skip_header=False)\n",
    "    print(data)\n",
    "    impute_type = get_type(type)\n",
    "\n",
    "\n",
    "    if impute_type == \"mean\":\n",
    "        # Impute missing values with column means\n",
    "        col_means = np.nanmean(data, axis=0)  # Compute column means while ignoring NaNs\n",
    "        nan_indices = np.isnan(data)  # Find indices of missing values\n",
    "\n",
    "        data[nan_indices] = np.take(col_means, np.where(nan_indices)[1])  \n",
    "\n",
    "\n",
    "\n",
    "    elif impute_type == \"mice\":\n",
    "        # Initialize the MICE imputer\n",
    "        mice_imputer = IterativeImputer()\n",
    "        # Impute missing values\n",
    "        data = mice_imputer.fit_transform(data)\n",
    "\n",
    "    elif impute_type == \"zero\":\n",
    "\n",
    "        # Impute missing values with zeros\n",
    "        data[np.isnan(data)] = 0\n",
    "\n",
    "    \n",
    "    means = np.mean(data, axis=0)\n",
    "    # Calculate covariance matrix\n",
    "    covariance_matrix = np.cov(data, rowvar=False)\n",
    "    # Write parameters to files\n",
    "    np.savetxt(type + \"cov.txt\", covariance_matrix, delimiter=',', fmt='%f')\n",
    "    np.savetxt(type + \"mu.txt\", means, delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list = [\"banknote\",\"climate_model_crashes\",\"connectionist_bench_sonar\",\"qsar_biodegradation\",\"yeast\"]\n",
    "reg_list = ['concrete_compression','wine_quality_red','wine_quality_white','yacht_hydrodynamics']\n",
    "type_list =  [\"diffuse\",\"logistic\",\"mar\",\"mcar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefilled_data/mean/banknote/diffuse\n",
      "prefilled_data/mice/banknote/diffuse\n",
      "prefilled_data/zero/banknote/diffuse\n",
      "prefilled_data/mean/banknote/logistic\n",
      "prefilled_data/mice/banknote/logistic\n",
      "prefilled_data/zero/banknote/logistic\n",
      "prefilled_data/mean/banknote/mar\n",
      "prefilled_data/mice/banknote/mar\n",
      "prefilled_data/zero/banknote/mar\n",
      "prefilled_data/mean/banknote/mcar\n",
      "prefilled_data/mice/banknote/mcar\n",
      "prefilled_data/zero/banknote/mcar\n",
      "prefilled_data/mean/climate_model_crashes/diffuse\n",
      "prefilled_data/mice/climate_model_crashes/diffuse\n",
      "prefilled_data/zero/climate_model_crashes/diffuse\n",
      "prefilled_data/mean/climate_model_crashes/logistic\n",
      "prefilled_data/mice/climate_model_crashes/logistic\n",
      "prefilled_data/zero/climate_model_crashes/logistic\n",
      "prefilled_data/mean/climate_model_crashes/mar\n",
      "prefilled_data/mice/climate_model_crashes/mar\n",
      "prefilled_data/zero/climate_model_crashes/mar\n",
      "prefilled_data/mean/climate_model_crashes/mcar\n",
      "prefilled_data/mice/climate_model_crashes/mcar\n",
      "prefilled_data/zero/climate_model_crashes/mcar\n",
      "prefilled_data/mean/connectionist_bench_sonar/diffuse\n",
      "prefilled_data/mice/connectionist_bench_sonar/diffuse\n",
      "prefilled_data/zero/connectionist_bench_sonar/diffuse\n",
      "prefilled_data/mean/connectionist_bench_sonar/logistic\n",
      "prefilled_data/mice/connectionist_bench_sonar/logistic\n",
      "prefilled_data/zero/connectionist_bench_sonar/logistic\n",
      "prefilled_data/mean/connectionist_bench_sonar/mar\n",
      "prefilled_data/mice/connectionist_bench_sonar/mar\n",
      "prefilled_data/zero/connectionist_bench_sonar/mar\n",
      "prefilled_data/mean/connectionist_bench_sonar/mcar\n",
      "prefilled_data/mice/connectionist_bench_sonar/mcar\n",
      "prefilled_data/zero/connectionist_bench_sonar/mcar\n",
      "prefilled_data/mean/qsar_biodegradation/diffuse\n",
      "prefilled_data/mice/qsar_biodegradation/diffuse\n",
      "prefilled_data/zero/qsar_biodegradation/diffuse\n",
      "prefilled_data/mean/qsar_biodegradation/logistic\n",
      "prefilled_data/mice/qsar_biodegradation/logistic\n",
      "prefilled_data/zero/qsar_biodegradation/logistic\n",
      "prefilled_data/mean/qsar_biodegradation/mar\n",
      "prefilled_data/mice/qsar_biodegradation/mar\n",
      "prefilled_data/zero/qsar_biodegradation/mar\n",
      "prefilled_data/mean/qsar_biodegradation/mcar\n",
      "prefilled_data/mice/qsar_biodegradation/mcar\n",
      "prefilled_data/zero/qsar_biodegradation/mcar\n",
      "prefilled_data/mean/yeast/diffuse\n",
      "prefilled_data/mice/yeast/diffuse\n",
      "prefilled_data/zero/yeast/diffuse\n",
      "prefilled_data/mean/yeast/logistic\n",
      "prefilled_data/mice/yeast/logistic\n",
      "prefilled_data/zero/yeast/logistic\n",
      "prefilled_data/mean/yeast/mar\n",
      "prefilled_data/mice/yeast/mar\n",
      "prefilled_data/zero/yeast/mar\n",
      "prefilled_data/mean/yeast/mcar\n",
      "prefilled_data/mice/yeast/mcar\n",
      "prefilled_data/zero/yeast/mcar\n"
     ]
    }
   ],
   "source": [
    "# clf data\n",
    "for name in clf_list:\n",
    "    for type in type_list:\n",
    "        dataname = name+\"_\"+type\n",
    "        for imptype in [\"mean\",\"mice\",\"zero\"]:\n",
    "            #print(name,type,imptype)\n",
    "            path = \"prefilled_data/{}/{}/{}\".format(imptype,name,type)\n",
    "            print(path)\n",
    "            os.makedirs(path)\n",
    "\n",
    "            run_norm(\"{}/train_data.txt\".format(dataname),\"{}/{}_\".format(dataname,imptype))\n",
    "            # # run_norm(\"data/train_data.txt\",\"data/mice_\")\n",
    "            # # run_norm(\"data/train_data.txt\",\"data/zero_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in data_list:\n",
    "    for type in type_list:\n",
    "        dataname = name+\"_\"+type\n",
    "        for imptype in [\"mean\",\"mice\",\"zero\"]:\n",
    "            print(dataname)\n",
    "            run_norm(\"{}/train_data.txt\".format(dataname),\"{}/{}_\".format(dataname,imptype))\n",
    "            # run_norm(\"data/train_data.txt\",\"data/mice_\")\n",
    "            # run_norm(\"data/train_data.txt\",\"data/zero_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -5.441399999999999793e+00 7.236299999999999955e+00 1.093800000000000050e-01 nan\n",
      "0  1.040000000000000036e+00 -6.932100000000000151...                             \n",
      "1  1.787500000000000089e+00 4.780000000000000249e...                             \n",
      "2  5.045200000000000351e+00 3.896399999999999864e...                             \n",
      "3  -1.788599999999999968e+00 -6.34860000000000024...                             \n",
      "4  -6.508399999999999963e+00 8.769600000000000506...                             \n"
     ]
    }
   ],
   "source": [
    "df_train_data = pd.read_csv('banknote_diffuse/train_data.txt')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df_train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.4414  ,  7.2363  ,  0.10938 ,       nan],\n",
       "       [ 1.04    , -6.9321  ,  8.2888  , -1.2991  ],\n",
       "       [ 1.7875  ,  4.78    ,       nan, -3.2362  ],\n",
       "       ...,\n",
       "       [ 1.6426  ,  3.0149  ,  0.22849 , -0.147   ],\n",
       "       [-2.0149  ,  3.6874  ,       nan,       nan],\n",
       "       [-5.1661  ,  8.0433  ,  0.044265,       nan]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.genfromtxt('banknote_diffuse/train_data.txt', delimiter=' ', skip_header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
