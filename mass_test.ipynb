{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from masskernal import M0_Kernel\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import pandas as pd \n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_value = None\n",
    "data_stats = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chess_shuffled_test.csv.toml',\n",
       " 'chess_shuffled_test.csv',\n",
       " 'nursery_test_shuffled.csv',\n",
       " 'bcw_fixed_missing_values.csv',\n",
       " 'nursery_test.csv.toml',\n",
       " 'abalone_test.csv',\n",
       " 'abalone_test.csv.toml']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"for_echo/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(\"for_echo/data/abalone_test.csv\")\n",
    "banknote = {\"X\":np.load(\"masstest/BNfeature.npy\"), \"Y\":np.load(\"masstest/BNlabel.npy\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone = pd.read_csv(\"for_echo/data/abalone_test.csv\",header = None)\n",
    "abalone = {\"X\":np.array(abalone.iloc[:, :-1]),\n",
    "            \"Y\":np.array(abalone.iloc[:, -1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import KernelPCA\n",
    "# Step 1: Generate synthetic dataset\n",
    "syn_1 = dict(zip([\"X\", \"Y\"], \n",
    "                 make_classification(n_samples=5000, \n",
    "                                     n_features=20, \n",
    "                                     n_informative=2, \n",
    "                                     n_redundant=2, \n",
    "                                     random_state=42)))\n",
    "\n",
    "\n",
    "syn_2 = dict(zip([\"X\", \"Y\"], \n",
    "                 make_classification(n_samples=1000, \n",
    "                                     n_features=10, \n",
    "                                     n_informative=5, \n",
    "                                     n_redundant=5, \n",
    "                                     random_state=42)))\n",
    "\n",
    "\n",
    "\n",
    "syn_3 = dict(zip([\"X\", \"Y\"], \n",
    "                 make_classification(n_samples=5000, \n",
    "                                     n_features=20, \n",
    "                                     n_informative=10, \n",
    "                                     n_redundant=5, \n",
    "                                     random_state=42)))\n",
    "data_stats = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_missing(data, rate = 0.1, type = \"mcar\"):\n",
    "    missing_rate = rate  # 10% of the data will be missing\n",
    "    # Calculate the number of elements to set as missing\n",
    "    total_elements = data.size\n",
    "    missing_elements = int(total_elements * missing_rate)\n",
    "\n",
    "    # Create a random mask\n",
    "    #np.random.seed(1)\n",
    "\n",
    "    if type == \"mcar\":\n",
    "        mask_indices = np.random.choice(total_elements, missing_elements, replace=False)\n",
    "\n",
    "        # Convert flat indices to multi-dimensional indices\n",
    "        multi_indices = np.unravel_index(mask_indices, data.shape)\n",
    "\n",
    "        # Set selected elements to NaN\n",
    "        data[multi_indices] = np.nan\n",
    "    elif type == \"mnar\":\n",
    "        for col in range(data.shape[1]):\n",
    "            column_data = data[:, col]\n",
    "            median_value = np.percentile(column_data, 60)\n",
    "            #print(len(upper_quantile_indices))\n",
    "            upper_quantile_indices = np.where(column_data > median_value)[0]\n",
    "            missingnum = int(missing_elements/data.shape[1])\n",
    "\n",
    "            selected_indices = np.random.choice(upper_quantile_indices,missingnum , replace=False)\n",
    "            data[selected_indices, col] = np.nan\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([83, 53, 70, 45, 44, 39, 22, 80, 10,  0, 18, 30, 73, 33, 90,  4, 76,\n",
       "       77, 12, 31])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "m0_krn = M0_Kernel(None, data_stats)\n",
    "m0_krn.set_nbins(param_value)\n",
    "\n",
    "modify_krn = Modify_Kernel(None, data_stats)\n",
    "modify_krn.set_nbins(param_value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syn 1 (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.8408\n",
      "Mean Cross-Validation Accuracy: 0.8410\n",
      "Mean Cross-Validation F1 Score: 0.7866\n",
      "Mean Cross-Validation Accuracy: 0.7870\n",
      "Mean Cross-Validation F1 Score: 0.7403\n",
      "Mean Cross-Validation Accuracy: 0.7410\n"
     ]
    }
   ],
   "source": [
    "## M0 \n",
    "run_test(syn_1,0.05,\"m0\")\n",
    "run_test(syn_1,0.2,\"m0\")\n",
    "run_test(syn_1,0.5,\"m0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.8438\n",
      "Mean Cross-Validation Accuracy: 0.8440\n",
      "Mean Cross-Validation F1 Score: 0.8049\n",
      "Mean Cross-Validation Accuracy: 0.8050\n",
      "Mean Cross-Validation F1 Score: 0.7215\n",
      "Mean Cross-Validation Accuracy: 0.7220\n"
     ]
    }
   ],
   "source": [
    "## Modify\n",
    "run_test(syn_1,0.05,\"mo\")\n",
    "run_test(syn_1,0.2,\"mo\")\n",
    "run_test(syn_1,0.5,\"mo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syn2 (small dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.8391\n",
      "Mean Cross-Validation Accuracy: 0.8400\n",
      "Mean Cross-Validation F1 Score: 0.7789\n",
      "Mean Cross-Validation Accuracy: 0.7800\n",
      "Mean Cross-Validation F1 Score: 0.7047\n",
      "Mean Cross-Validation Accuracy: 0.7050\n"
     ]
    }
   ],
   "source": [
    "## M0 \n",
    "run_test(syn_2,0.05,\"m0\")\n",
    "run_test(syn_2,0.2,\"m0\")\n",
    "run_test(syn_2,0.5,\"m0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.8194\n",
      "Mean Cross-Validation Accuracy: 0.8200\n",
      "Mean Cross-Validation F1 Score: 0.7097\n",
      "Mean Cross-Validation Accuracy: 0.7100\n",
      "Mean Cross-Validation F1 Score: 0.7378\n",
      "Mean Cross-Validation Accuracy: 0.7400\n"
     ]
    }
   ],
   "source": [
    "## Modify\n",
    "run_test(syn_2,0.05,\"mo\")\n",
    "run_test(syn_2,0.2,\"mo\")\n",
    "run_test(syn_2,0.5,\"mo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syn3 (complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.7766\n",
      "Mean Cross-Validation Accuracy: 0.7770\n",
      "Mean Cross-Validation F1 Score: 0.6639\n",
      "Mean Cross-Validation Accuracy: 0.6640\n",
      "Mean Cross-Validation F1 Score: 0.6322\n",
      "Mean Cross-Validation Accuracy: 0.6330\n"
     ]
    }
   ],
   "source": [
    "## M0 \n",
    "run_test(syn_3,0.05,\"m0\")\n",
    "run_test(syn_3,0.2,\"m0\")\n",
    "run_test(syn_3,0.5,\"m0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.7517\n",
      "Mean Cross-Validation Accuracy: 0.7520\n",
      "Mean Cross-Validation F1 Score: 0.7066\n",
      "Mean Cross-Validation Accuracy: 0.7070\n",
      "Mean Cross-Validation F1 Score: 0.6247\n",
      "Mean Cross-Validation Accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "## Modify\n",
    "run_test(syn_3,0.05,\"mo\")\n",
    "run_test(syn_3,0.2,\"mo\")\n",
    "run_test(syn_3,0.5,\"mo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banknote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.8977\n",
      "Mean Cross-Validation Accuracy: 0.8982\n",
      "Mean Cross-Validation F1 Score: 0.7982\n",
      "Mean Cross-Validation Accuracy: 0.8000\n",
      "Mean Cross-Validation F1 Score: 0.7369\n",
      "Mean Cross-Validation Accuracy: 0.7382\n"
     ]
    }
   ],
   "source": [
    "## M0 \n",
    "run_test(banknote,0.05,\"m0\")\n",
    "run_test(banknote,0.2,\"m0\")\n",
    "run_test(banknote,0.5,\"m0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.8959\n",
      "Mean Cross-Validation Accuracy: 0.8982\n",
      "Mean Cross-Validation F1 Score: 0.7878\n",
      "Mean Cross-Validation Accuracy: 0.7927\n",
      "Mean Cross-Validation F1 Score: 0.6807\n",
      "Mean Cross-Validation Accuracy: 0.6873\n"
     ]
    }
   ],
   "source": [
    "## Modify\n",
    "run_test(banknote,0.05,\"mo\")\n",
    "run_test(banknote,0.2,\"mo\")\n",
    "run_test(banknote,0.5,\"mo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNAR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banknote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.8898\n",
      "Mean Cross-Validation Accuracy: 0.8909\n",
      "Mean Cross-Validation F1 Score: 0.8225\n",
      "Mean Cross-Validation Accuracy: 0.8255\n",
      "Mean Cross-Validation F1 Score: 0.8315\n",
      "Mean Cross-Validation Accuracy: 0.8327\n"
     ]
    }
   ],
   "source": [
    "## M0 \n",
    "run_test(banknote,0.05,\"m0\",\"mnar\")\n",
    "run_test(banknote,0.1,\"m0\",\"mnar\")\n",
    "run_test(banknote,0.3,\"m0\",\"mnar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.9633\n",
      "Mean Cross-Validation Accuracy: 0.9636\n",
      "Mean Cross-Validation F1 Score: 0.9598\n",
      "Mean Cross-Validation Accuracy: 0.9600\n",
      "Mean Cross-Validation F1 Score: 0.9414\n",
      "Mean Cross-Validation Accuracy: 0.9418\n"
     ]
    }
   ],
   "source": [
    "## Modify\n",
    "run_test(banknote,0.05,\"mo\",\"mnar\")\n",
    "run_test(banknote,0.1,\"mo\",\"mnar\")\n",
    "run_test(banknote,0.3,\"mo\",\"mnar\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation MSE: 6.3448\n",
      "Mean Cross-Validation MAE: 1.8271\n",
      "Test MSE: 5.8865\n",
      "Test MAE: 1.7342\n",
      "Mean Cross-Validation MSE: 6.3125\n",
      "Mean Cross-Validation MAE: 1.8461\n",
      "Test MSE: 6.1168\n",
      "Test MAE: 1.7896\n",
      "Mean Cross-Validation MSE: 8.0736\n",
      "Mean Cross-Validation MAE: 2.0727\n",
      "Test MSE: 7.2214\n",
      "Test MAE: 1.9593\n"
     ]
    }
   ],
   "source": [
    "## M0 \n",
    "run_test_reg(abalone,0.05,\"m0\",\"mnar\")\n",
    "run_test_reg(abalone,0.1,\"m0\",\"mnar\")\n",
    "run_test_reg(abalone,0.3,\"m0\",\"mnar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation MSE: 6.5777\n",
      "Mean Cross-Validation MAE: 1.8479\n",
      "Test MSE: 5.9846\n",
      "Test MAE: 1.7535\n",
      "Mean Cross-Validation MSE: 6.4865\n",
      "Mean Cross-Validation MAE: 1.8725\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[169], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## Modify\u001b[39;00m\n\u001b[1;32m      2\u001b[0m run_test_reg(abalone,\u001b[39m0.05\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mmo\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mmnar\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m run_test_reg(abalone,\u001b[39m0.1\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mmo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mmnar\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m run_test_reg(abalone,\u001b[39m0.3\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mmo\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mmnar\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[167], line 52\u001b[0m, in \u001b[0;36mrun_test_reg\u001b[0;34m(data, missing_rate, kernalname, mtype)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMean Cross-Validation MAE: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mmean(mae_scores)\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[39m# Train the model on the full training data\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m rf\u001b[39m.\u001b[39;49mfit(X_kpca_train, train_Y)\n\u001b[1;32m     54\u001b[0m \u001b[39m# Predict on the test data\u001b[39;00m\n\u001b[1;32m     55\u001b[0m y_pred \u001b[39m=\u001b[39m rf\u001b[39m.\u001b[39mpredict(X_kpca_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mass/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mass/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    490\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    491\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    492\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    493\u001b[0m )(\n\u001b[1;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    495\u001b[0m         t,\n\u001b[1;32m    496\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    497\u001b[0m         X,\n\u001b[1;32m    498\u001b[0m         y,\n\u001b[1;32m    499\u001b[0m         sample_weight,\n\u001b[1;32m    500\u001b[0m         i,\n\u001b[1;32m    501\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    502\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    503\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    504\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39;49mmissing_values_in_feature_mask,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    508\u001b[0m )\n\u001b[1;32m    510\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mass/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mass/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mass/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mass/lib/python3.11/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mass/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     tree\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    193\u001b[0m         X,\n\u001b[1;32m    194\u001b[0m         y,\n\u001b[1;32m    195\u001b[0m         sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight,\n\u001b[1;32m    196\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39;49mmissing_values_in_feature_mask,\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[39m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mass/lib/python3.11/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Modify\n",
    "run_test_reg(abalone,0.05,\"mo\",\"mnar\")\n",
    "run_test_reg(abalone,0.1,\"mo\",\"mnar\")\n",
    "run_test_reg(abalone,0.3,\"mo\",\"mnar\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.8380\n",
      "Mean Cross-Validation Accuracy: 0.8380\n",
      "Mean Cross-Validation F1 Score: 0.8229\n",
      "Mean Cross-Validation Accuracy: 0.8230\n",
      "Mean Cross-Validation F1 Score: 0.7855\n",
      "Mean Cross-Validation Accuracy: 0.7860\n"
     ]
    }
   ],
   "source": [
    "## M0 \n",
    "run_test(syn_1,0.05,\"m0\",\"mnar\")\n",
    "run_test(syn_1,0.1,\"m0\",\"mnar\")\n",
    "run_test(syn_1,0.3,\"m0\",\"mnar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.8557\n",
      "Mean Cross-Validation Accuracy: 0.8560\n",
      "Mean Cross-Validation F1 Score: 0.8678\n",
      "Mean Cross-Validation Accuracy: 0.8680\n",
      "Mean Cross-Validation F1 Score: 0.8728\n",
      "Mean Cross-Validation Accuracy: 0.8730\n"
     ]
    }
   ],
   "source": [
    "## Modify\n",
    "run_test(syn_1,0.05,\"mo\",\"mnar\")\n",
    "run_test(syn_1,0.1,\"mo\",\"mnar\")\n",
    "run_test(syn_1,0.3,\"mo\",\"mnar\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.8187\n",
      "Mean Cross-Validation Accuracy: 0.8200\n",
      "Mean Cross-Validation F1 Score: 0.8046\n",
      "Mean Cross-Validation Accuracy: 0.8050\n",
      "Mean Cross-Validation F1 Score: 0.6957\n",
      "Mean Cross-Validation Accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "## M0 \n",
    "run_test(syn_2,0.05,\"m0\",\"mnar\")\n",
    "run_test(syn_2,0.1,\"m0\",\"mnar\")\n",
    "run_test(syn_2,0.3,\"m0\",\"mnar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.8397\n",
      "Mean Cross-Validation Accuracy: 0.8400\n",
      "Mean Cross-Validation F1 Score: 0.8349\n",
      "Mean Cross-Validation Accuracy: 0.8350\n",
      "Mean Cross-Validation F1 Score: 0.8744\n",
      "Mean Cross-Validation Accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "## Modify\n",
    "run_test(syn_2,0.05,\"mo\",\"mnar\")\n",
    "run_test(syn_2,0.1,\"mo\",\"mnar\")\n",
    "run_test(syn_2,0.3,\"mo\",\"mnar\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.7175\n",
      "Mean Cross-Validation Accuracy: 0.7180\n",
      "Mean Cross-Validation F1 Score: 0.6747\n",
      "Mean Cross-Validation Accuracy: 0.6750\n",
      "Mean Cross-Validation F1 Score: 0.6165\n",
      "Mean Cross-Validation Accuracy: 0.6170\n"
     ]
    }
   ],
   "source": [
    "## M0 \n",
    "run_test(syn_3,0.05,\"m0\",\"mnar\")\n",
    "run_test(syn_3,0.1,\"m0\",\"mnar\")\n",
    "run_test(syn_3,0.3,\"m0\",\"mnar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation F1 Score: 0.7997\n",
      "Mean Cross-Validation Accuracy: 0.8000\n",
      "Mean Cross-Validation F1 Score: 0.8159\n",
      "Mean Cross-Validation Accuracy: 0.8160\n",
      "Mean Cross-Validation F1 Score: 0.8258\n",
      "Mean Cross-Validation Accuracy: 0.8260\n"
     ]
    }
   ],
   "source": [
    "## Modify\n",
    "run_test(syn_3,0.05,\"mo\",\"mnar\")\n",
    "run_test(syn_3,0.1,\"mo\",\"mnar\")\n",
    "run_test(syn_3,0.3,\"mo\",\"mnar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(data,missing_rate,kernalname = \"mo\",mtype = \"mcar\"):\n",
    "    X = data[\"X\"]\n",
    "    Y = data[\"Y\"]\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    train_X = make_missing(train_X,rate = missing_rate,type = mtype)\n",
    "    test_X = make_missing(test_X,rate = missing_rate,type = mtype)\n",
    "    # modify_krn = Modify_Kernel(None, data_stats)\n",
    "    # modify_krn.set_nbins(param_value)\n",
    "    if kernalname == \"m0\":\n",
    "        kernal = M0_Kernel(None, data_stats)\n",
    "        kernal.set_nbins(param_value)\n",
    "    else:\n",
    "        kernal = Modify_Kernel(None, data_stats)\n",
    "        kernal.set_nbins(param_value)\n",
    "\n",
    "    train_mod, test_mod = kernal.build_model(train_X, test_X)  # this does the pre-processing step\n",
    "\n",
    "    sim_train = kernal.transform(train_mod)\n",
    "    sim_test = kernal.transform(test_mod,train_mod)  # row = train, col = test\n",
    "\n",
    "\n",
    "\n",
    "    # Configure Kernel PCA for precomputed kernels\n",
    "    kpca = KernelPCA(kernel='precomputed')\n",
    "\n",
    "    # Transform data using Kernel PCA\n",
    "    X_kpca_train = kpca.fit_transform(sim_train)\n",
    "    X_kpca_test = kpca.transform(sim_test)\n",
    "\n",
    "\n",
    "    #  Calculate F1 score and accuracy\n",
    "    # Initialize the RandomForest classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = cross_val_score(rf, X_kpca_test, test_Y, cv=cv, scoring='f1_macro')\n",
    "    acc_scores = cross_val_score(rf, X_kpca_test, test_Y, cv=cv, scoring='accuracy')\n",
    "\n",
    "    # Print mean F1 score and accuracy\n",
    "    print(f\"Mean Cross-Validation F1 Score: {np.mean(f1_scores):.4f}\")\n",
    "    print(f\"Mean Cross-Validation Accuracy: {np.mean(acc_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def run_test_reg(data,missing_rate,kernalname = \"mo\",mtype = \"mcar\"):\n",
    "    X = data[\"X\"]\n",
    "    Y = data[\"Y\"]\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    train_X = make_missing(train_X,rate = missing_rate,type = mtype)\n",
    "    test_X = make_missing(test_X,rate = missing_rate,type = mtype)\n",
    "    # modify_krn = Modify_Kernel(None, data_stats)\n",
    "    # modify_krn.set_nbins(param_value)\n",
    "    if kernalname == \"m0\":\n",
    "        kernal = M0_Kernel(None, data_stats)\n",
    "        kernal.set_nbins(param_value)\n",
    "    else:\n",
    "        kernal = Modify_Kernel(None, data_stats)\n",
    "        kernal.set_nbins(param_value)\n",
    "\n",
    "    train_mod, test_mod = kernal.build_model(train_X, test_X)  # this does the pre-processing step\n",
    "\n",
    "    sim_train = kernal.transform(train_mod)\n",
    "    sim_test = kernal.transform(test_mod,train_mod)  # row = train, col = test\n",
    "\n",
    "\n",
    "\n",
    "    # Configure Kernel PCA for precomputed kernels\n",
    "    kpca = KernelPCA(kernel='precomputed')\n",
    "\n",
    "    # Transform data using Kernel PCA\n",
    "    X_kpca_train = kpca.fit_transform(sim_train)\n",
    "    X_kpca_test = kpca.transform(sim_test)\n",
    "\n",
    "    # Initialize the RandomForest regressor\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(rf, X_kpca_test, test_Y, cv=cv, scoring='neg_mean_squared_error')\n",
    "    mae_scores = cross_val_score(rf, X_kpca_test, test_Y, cv=cv, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    # Print mean MSE and MAE\n",
    "    print(f\"Mean Cross-Validation MSE: {-np.mean(mse_scores):.4f}\")\n",
    "    print(f\"Mean Cross-Validation MAE: {-np.mean(mae_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_distance(num, compare_to):\n",
    "    # Calculate absolute differences\n",
    "    distance_to_zero = abs(num - 0)\n",
    "    distance_to_compare = abs(num - compare_to)\n",
    "\n",
    "    # Determine which is closer\n",
    "    if distance_to_zero > distance_to_compare:\n",
    "        return 0\n",
    "    elif distance_to_zero < distance_to_compare:\n",
    "        return compare_to-1\n",
    "    else:\n",
    "        return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Kernal F1 Score: 1.0000\n",
      "After Kernal Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Kernal F1 Score: 1.0000\n",
      "After Kernal Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier using the Kernel PCA transformed data\n",
    "rf.fit(sim_train, train_Y)\n",
    "# Predict using the precomputed test kernel matrix\n",
    "y_pred = rf.predict(sim_test)\n",
    "f1 = f1_score(test_Y, y_pred,average=\"macro\")\n",
    "acc = accuracy_score(test_Y, y_pred)\n",
    "\n",
    "\n",
    "print(f\"After Kernal F1 Score: {f1:.4f}\")\n",
    "print(f\"After Kernal Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import c_float\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# try:\n",
    "#     import pymp\n",
    "#     pymp_found = True\n",
    "# except ImportError as e:\n",
    "#     pymp_found = False\n",
    "\n",
    "\n",
    "#from .equal_freq_discretization import EqualFrequencyDiscretizer\n",
    "\n",
    "\n",
    "class Modify_Kernel:\n",
    "    def __init__(self, nbins = None, stats = None):\n",
    "        self.nbins_ = nbins\n",
    "        self.stats_ = stats\n",
    "\n",
    "    def build_model(self, train, test):\n",
    "\n",
    "        # if data missing, 0 will be inputed\n",
    "        def get_bin_dissimilarity():\n",
    "            bin_dissim = [[] for i in range(self.ndim_)]\n",
    "            max_num_bins = max(self.num_bins_)\n",
    "\n",
    "            for i in range(self.ndim_):\n",
    "                n_bins = self.num_bins_[i]\n",
    "                bin_cf = [0 for j in range(n_bins)]\n",
    "                cf = 0\n",
    "\n",
    "                if (self.stats_ is not None) and (\"Nominal\" in self.stats_[\"attribute\"][i][\"type\"]):\n",
    "                    for j in range(n_bins):\n",
    "                        bin_cf[j] = self.bin_counts_[i][j]\n",
    "                else:\n",
    "                    for j in range(n_bins):\n",
    "                        cf = cf + self.bin_counts_[i][j]\n",
    "                        bin_cf[j] = cf\n",
    "\n",
    "                b_mass = [[0.0 for j in range(max_num_bins)] for k in range(max_num_bins)]\n",
    "\n",
    "                for j in range(n_bins):\n",
    "                    for k in range(j, n_bins):\n",
    "                        if (self.stats_ is not None) and (\"Nominal\" in self.stats_[\"attribute\"][i][\"type\"]):\n",
    "                            if j == k:\n",
    "                                prob_mass = (bin_cf[k] + 1) / (self.ndata_ + n_bins)\n",
    "                            else:\n",
    "                                prob_mass = (bin_cf[k] + bin_cf[j] + 1) / (self.ndata_ + n_bins)\n",
    "                        else:\n",
    "                            prob_mass = (bin_cf[k] - bin_cf[j] + self.bin_counts_[i][j] + 1) / (self.ndata_ + n_bins)\n",
    "\n",
    "                        b_mass[j][k] = np.log(prob_mass)\n",
    "                        b_mass[k][j] = b_mass[j][k]\n",
    "\n",
    "                bin_dissim[i] = b_mass\n",
    "            return np.array(bin_dissim)\n",
    "\n",
    "        self.ndata_ = len(train) # number of train instance\n",
    "        self.ndim_ = len(train[0]) # number of train column\n",
    "\n",
    "        if self.nbins_ is None: # pre-define bin numbers\n",
    "            self.nbins_ = int(np.log2(self.ndata_) + 1)\n",
    "\n",
    "\n",
    "        self.dimVec_ = np.array([i for i in range(self.ndim_)])\n",
    "        self.discretiser_ = EqualFrequencyDiscretizer(train, self.nbins_, self.stats_)\n",
    "        self.bin_cuts_, self.bin_counts_ = self.discretiser_.get_bin_cuts_counts()\n",
    "        self.num_bins_ = self.discretiser_.get_num_bins()\n",
    "        self.bin_dissimilarities_ = get_bin_dissimilarity()\n",
    "\n",
    "        new_test = []\n",
    "\n",
    "        for i in range(len(test)):\n",
    "            # make each column into bin_id\n",
    "            new_test.append(self.discretiser_.get_bin_id(test[i, :]))\n",
    "        \n",
    "        \n",
    "        return self.discretiser_.get_data_bin_id(), np.array(new_test, dtype = c_float, order = \"C\")\n",
    "\n",
    "    def set_nbins(self, nbins):\n",
    "        self.nbins_ = nbins\n",
    "\n",
    "    def transform(self, train, test=None):\n",
    "        def convert(x_bin_ids, y_bin_ids):\n",
    "            if -1 in x_bin_ids or -1 in y_bin_ids:\n",
    "                for i, bin_id in enumerate(x_bin_ids):\n",
    "                    if bin_id == -1:\n",
    "                        #print(\"Before\",i,bin_id,y_bin_ids[i])\n",
    "                        x_bin_ids[i] = max_distance(bin_id, self.nbins_)\n",
    "                        #print(\"After\",i,x_bin_ids[i],y_bin_ids[i])\n",
    "                    elif y_bin_ids[i] == -1:\n",
    "                        #print(\"Before\",i,bin_id,y_bin_ids[i])\n",
    "                        y_bin_ids[i] = max_distance(bin_id, self.nbins_)\n",
    "                        #print(\"After\",i,x_bin_ids[i],y_bin_ids[i])\n",
    "                    elif (bin_id == -1) and (y_bin_ids[i] == -1):\n",
    "                        #print(\"Before\",i,bin_id,y_bin_ids[i])\n",
    "                        y_bin_ids[i] = self.nbins_\n",
    "                        x_bin_ids[i] = 0\n",
    "                        #print(\"After\",i,x_bin_ids[i],y_bin_ids[i])\n",
    "                return x_bin_ids, y_bin_ids\n",
    "            else:\n",
    "                return x_bin_ids, y_bin_ids\n",
    "        def dissimilarity(x_bin_ids, y_bin_ids):\n",
    "            len_x, len_y = len(x_bin_ids), len(y_bin_ids)\n",
    "\n",
    "            # check the vector size\n",
    "            if (len_x != self.ndim_) or (len_y != self.ndim_):\n",
    "                raise IndexError(\"Number of columns does not match.\")\n",
    "\n",
    "            m_dissim = self.bin_dissimilarities_[self.dimVec_, x_bin_ids.astype(int), y_bin_ids.astype(int)]\n",
    "            return np.sum(m_dissim) / self.ndim_\n",
    "\n",
    "        \n",
    "\n",
    "        if test is None:\n",
    "            d = np.empty((len(train), len(train)))\n",
    "            x_x = [0.0 for i in range(len(train))]\n",
    "            x_xi = [0.0 for i in range(len(train))]\n",
    "            x_xj = [0.0 for i in range(len(train))]\n",
    "\n",
    "            for i in range(len(train)):\n",
    "                for j in range(i, len(train)):\n",
    "                    train[i], train[j] = convert(train[i], train[j]) \n",
    "                    # updated i and j\n",
    "                    x_y = dissimilarity(train[i], train[j])\n",
    "                    x_xi[i] = dissimilarity(train[i], train[i])\n",
    "                    x_xj[j] = dissimilarity(train[j], train[j])\n",
    "\n",
    "                    d[i][j] = (2.0 * x_y) / (x_xi[i] + x_xj[j])\n",
    "                    d[j][i] = d[i][j]\n",
    "        else:\n",
    "            d = np.empty((len(train), len(test)))\n",
    "            y_y = [0.0 for i in range(len(test))]\n",
    "\n",
    "            for i in range(len(train)):\n",
    "                for j in range(len(test)):\n",
    "                    train[i], test[j] = convert(train[i], test[j])\n",
    "                    x_x = dissimilarity(train[i], train[i])\n",
    "                    y_y[j] = dissimilarity(test[j], test[j])\n",
    "\n",
    "                    x_y = dissimilarity(train[i], test[j])\n",
    "\n",
    "                    d[i][j] = (2.0 * x_y) / (x_x + y_y[j])\n",
    "\n",
    "        return np.array(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import c_float\n",
    "\n",
    "import numpy as np\n",
    "from bisect import bisect_left\n",
    "\n",
    "\n",
    "class EqualFrequencyDiscretizer(object):\n",
    "\n",
    "  def __init__(self, data, nbins, stats):\n",
    "\n",
    "    self.stats = stats\n",
    "    self.n_data = len(data)\n",
    "    self.n_dim = len(data[0])\n",
    "    self.bin_cuts = [[] for i in range(self.n_dim)]\n",
    "    self.bin_counts = [[] for i in range(self.n_dim)]\n",
    "    self.data_bin_ids = np.array([[-1 for i in range(self.n_dim)] for i in range(self.n_data)])\n",
    "    # initialized with -1\n",
    "    self.num_bins = [0 for i in range(self.n_dim)]\n",
    "    for i in range(self.n_dim):\n",
    "      if (self.stats is None) or (\"Numeric\" in self.stats[\"attribute\"][i][\"type\"]):\n",
    "        column_data = data[:, i] # looking at each column\n",
    "        # Filter out NaN values from the column\n",
    "        temp = column_data[~np.isnan(column_data)]\n",
    "        b_cuts, b_counts = self.equal_freq_histograms(temp, nbins)\n",
    "        #b_cuts, b_counts = self.equal_freq_histograms(data[:, i], nbins)\n",
    "        # b_cuts, b_counts = self.equal_freq_histograms_weka(data[:,i], nbins)\n",
    "      else:\n",
    "        b_cuts, b_counts = self.equal_freq_histograms_non_numeric(data[:, i], i)\n",
    "\n",
    "      self.bin_cuts[i] = b_cuts\n",
    "      self.bin_counts[i] = b_counts\n",
    "      self.num_bins[i] = len(b_counts)\n",
    "      for j in range(self.n_data):\n",
    "        # for each column, look at each item\n",
    "        if (self.stats is None) or (\"Numeric\" in self.stats[\"attribute\"][i][\"type\"]):\n",
    "            if np.isnan(data[j, i]):\n",
    "              self.data_bin_ids[j,i] = -1\n",
    "            else:\n",
    "              self.data_bin_ids[j,i] = bisect_left(b_cuts[1:-1], data[j,i])\n",
    "        else:\n",
    "          self.data_bin_ids[j,i] = int(data[j,i])\n",
    "  def get_bin_cuts_counts(self):\n",
    "    return self.bin_cuts, self.bin_counts\n",
    "\n",
    "  def get_num_bins(self):\n",
    "    return self.num_bins \n",
    "\n",
    "  def get_data_bin_id(self):\n",
    "    return np.array(self.data_bin_ids, dtype = c_float)\n",
    "\n",
    "  def get_bin_id(self, x):\n",
    "    x_bin_ids = [-1 for i in range(self.n_dim)]\n",
    "    for i in range(self.n_dim):\n",
    "      if (self.stats is None) or (\"Numeric\" in self.stats[\"attribute\"][i][\"type\"]):\n",
    "        if np.isnan(x[i]):\n",
    "              x_bin_ids[i] = -1\n",
    "        else:\n",
    "          cuts = self.bin_cuts[i]\n",
    "          x_bin_ids[i] = bisect_left(cuts[1:-1], x[i])\n",
    "      else:\n",
    "        x_bin_ids[i] = int(x[i])\n",
    "\n",
    "    return np.array(x_bin_ids)\n",
    "\n",
    "  def equal_freq_histograms_non_numeric(self, x, idx):\n",
    "    # get unique values and counts\n",
    "    unique_values, unique_value_counts = np.unique(x, return_counts = True)\n",
    "\n",
    "    if (self.stats is not None) and (\"Numeric\" not in self.stats[\"attribute\"][idx][\"type\"]):\n",
    "      chk_cnt = []\n",
    "      idx_chk = 0\n",
    "\n",
    "      for i in range(len(self.stats[\"attribute\"][idx][\"values\"])):\n",
    "        if (idx_chk < len(unique_values)) and (unique_values[idx_chk] == i):\n",
    "          chk_cnt.append(unique_value_counts[idx_chk])\n",
    "          idx_chk += 1\n",
    "        else:\n",
    "          chk_cnt.append(0)\n",
    "\n",
    "      unique_value_counts = chk_cnt\n",
    "\n",
    "    # return the result\n",
    "    return np.array([]), np.array(unique_value_counts)\n",
    "\n",
    "\n",
    "  def equal_freq_histograms(self, x, nbins):\n",
    "\n",
    "    b_cuts = []\n",
    "    b_counts = []\n",
    "\n",
    "    # get unique values and counts\n",
    "    unique_values, unique_value_counts = np.unique(x, return_counts=True)\n",
    "    num_unique_vals = len(unique_values)\n",
    "\n",
    "    # start discretization\n",
    "    x_size = len(x)\n",
    "    exp_freq = x_size/nbins\n",
    "    freq_count = 0\n",
    "    last_freq_count = 0\n",
    "    last_id = -1\n",
    "    cut_point_id = 0\n",
    "\n",
    "    b_cuts.append(unique_values[0] - (unique_values[1] - unique_values[0]) / 2)\n",
    "\n",
    "    for i in range(num_unique_vals-1):\n",
    "      freq_count += unique_value_counts[i]\n",
    "      x_size -= unique_value_counts[i]\n",
    "      # check if ideal bin count is reached\n",
    "      if (freq_count >= exp_freq):\n",
    "        # check if this one is worst than the last one\n",
    "        if (((exp_freq - last_freq_count) < (freq_count - exp_freq)) and (last_id != -1) ):\n",
    "          cut_point = (unique_values[last_id] + unique_values[last_id+1])/2\n",
    "          # check if it worths merging the about to create bin with the last bin\n",
    "          if (len(b_counts) > 1):\n",
    "            if ((abs(b_counts[-1] + last_freq_count) - exp_freq) < abs(last_freq_count - exp_freq)):\n",
    "              b_counts[-1] += last_freq_count\n",
    "              b_cuts[-1] = cut_point\n",
    "            else: \n",
    "              b_cuts.append(cut_point)\n",
    "              b_counts.append(last_freq_count)\n",
    "          else:\n",
    "              b_cuts.append(cut_point)\n",
    "              b_counts.append(last_freq_count)              \n",
    "          freq_count -= last_freq_count\n",
    "          last_freq_count = freq_count\n",
    "          last_id = i\n",
    "        else:\n",
    "          b_cuts.append((unique_values[i] + unique_values[i+1])/2)\n",
    "          b_counts.append(freq_count)\n",
    "          freq_count = 0\n",
    "          last_freq_count = 0\n",
    "          last_id = -1\n",
    "        # increase the counter\n",
    "        cut_point_id += 1\n",
    "        # exp_freq = (x_size + freq_count) / (nbins - cut_point_id)\n",
    "      else:  \n",
    "        last_id = i\n",
    "        last_freq_count = freq_count\n",
    "\n",
    "    # what to do with the last unique value frequency\n",
    "    last_unique_value_count = unique_value_counts[i+1] \n",
    "    freq_count = freq_count + last_unique_value_count\n",
    "    x_size -= unique_value_counts[i+1]\n",
    "\n",
    "    # Just make sure that it is the last unique value\n",
    "    if (x_size != 0):\n",
    "      print('ERROR: Something is wrong, x_size should be 0 but x_size=%s' % (x_size))\n",
    "      exit()\n",
    "     \n",
    "    # check if the next partition is required\n",
    "    if ((last_id != -1) and (abs(exp_freq - last_unique_value_count) < abs(freq_count - exp_freq))):\n",
    "      b_cuts.append((unique_values[last_id] + unique_values[last_id+1])/2)\n",
    "      b_counts.append(last_freq_count)\n",
    "      freq_count -= last_freq_count\n",
    "\n",
    "    b_counts.append(freq_count)\n",
    "     \n",
    "    # check if the last partition can be merged with the one before\n",
    "    if (len(b_counts) >= 2):    \n",
    "      if (abs((b_counts[-2] + b_counts[-1]) - exp_freq) < abs(exp_freq - b_counts[-1])): \n",
    "         b_counts[-2] += b_counts[-1]\n",
    "         del b_cuts[-1]\n",
    "         del b_counts[-1]\n",
    "\n",
    "    # check if it is worth merging the second last bin with the third last\n",
    "    if (len(b_counts) >= 3):\n",
    "      if (abs((b_counts[-3] + b_counts[-2]) - exp_freq) < abs(exp_freq - b_counts[-2])):\n",
    "        b_counts[-3] += b_counts[-2]\n",
    "        b_counts[-2] = b_counts[-1]\n",
    "        del b_cuts[-2]\n",
    "        del b_counts[-1]\n",
    "\n",
    "    b_cuts.append(unique_values[num_unique_vals-1] + (unique_values[num_unique_vals-1] - unique_values[num_unique_vals-2]) / 2) \n",
    "\n",
    "    assert sum(b_counts) == len(x)\n",
    "    assert len(b_cuts) == (len(b_counts) + 1)\n",
    "\n",
    "    # return the result\n",
    "    return np.array(b_cuts), np.array(b_counts)\n",
    "\n",
    "  def equal_freq_histograms_weka(self, x, nbins): # WEKA Implementation\n",
    "    b_cuts = []\n",
    "    b_counts = []\n",
    "    # get unique values and counts\n",
    "    unique_values, unique_value_counts = np.unique(x, return_counts=True)\n",
    "    num_unique_vals = len(unique_values)\n",
    "\n",
    "    x_size = len(x)\n",
    "    exp_freq = x_size/nbins\n",
    "    freq_count = 0\n",
    "    last_freq_count = 0\n",
    "    last_id = -1\n",
    "    cut_point_id = 0\n",
    "    for i in range(num_unique_vals-1):\n",
    "      freq_count += unique_value_counts[i]\n",
    "      x_size -= unique_value_counts[i]\n",
    "      # check if ideal bin count is reached\n",
    "      if (freq_count >= exp_freq):\n",
    "        # check if this one is worst than the last one\n",
    "        if (((exp_freq - last_freq_count) < (freq_count - exp_freq)) and (last_id != -1) ):\n",
    "          b_cuts.append((unique_values[last_id] + unique_values[last_id+1])/2)\n",
    "          b_counts.append(last_freq_count)\n",
    "          freq_count -= last_freq_count\n",
    "          last_freq_count = freq_count\n",
    "          last_id = i\n",
    "        else:\n",
    "          b_cuts.append((unique_values[i] + unique_values[i+1])/2)\n",
    "          b_counts.append(freq_count)\n",
    "          freq_count = 0\n",
    "          last_freq_count = 0\n",
    "          last_id = -1\n",
    "\n",
    "        cut_point_id += 1\n",
    "        exp_freq = (x_size + freq_count) / (nbins - cut_point_id)\n",
    "\n",
    "      else:  \n",
    "        last_id = i;\n",
    "        last_freq_count = freq_count;\n",
    "\n",
    "    freq_count += unique_value_counts[i+1]\n",
    "\n",
    "    # what to do with the last unique value\n",
    "    if ((cut_point_id < nbins) and (freq_count > exp_freq) and ((exp_freq - last_freq_count) < (freq_count - exp_freq))):\n",
    "      b_cuts.append((unique_values[last_id] + unique_values[last_id+1])/2)\n",
    "      b_counts.append(last_freq_count)\n",
    "      b_counts.append(freq_count-last_freq_count)\n",
    "    else:  \n",
    "      b_counts.append(freq_count)\n",
    "\n",
    "    return np.array(b_cuts), np.array(b_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            if test is None:\n",
    "                test = train\n",
    "                \n",
    "                d = np.empty((len(train), len(train)))\n",
    "                x_x = [0.0 for i in range(len(train))]\n",
    "\n",
    "                for i in range(len(train)):\n",
    "                    x_x[i] = dissimilarity(train[i], train[i])\n",
    "\n",
    "                for i in range(len(train)):\n",
    "                    for j in range(i, len(train)):\n",
    "                        x_y = dissimilarity(train[i], train[j])\n",
    "\n",
    "                        d[i][j] = (2.0 * x_y) / (x_x[i] + x_x[j])\n",
    "                        d[j][i] = d[i][j]\n",
    "            else:\n",
    "                d = np.empty((len(train), len(test)))\n",
    "                y_y = [0.0 for i in range(len(test))]\n",
    "\n",
    "                for i in range(len(test)):\n",
    "                    y_y[i] = dissimilarity(test[i], test[i])\n",
    "\n",
    "                for i in range(len(train)):\n",
    "                    x_x = dissimilarity(train[i], train[i])\n",
    "\n",
    "                    for j in range(len(test)):\n",
    "                        x_y = dissimilarity(train[i], test[j])\n",
    "\n",
    "                        d[i][j] = (2.0 * x_y) / (x_x + y_y[j])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
